export const metadata = {
  title: '동기화',
  description:
    'Firehose 및 기타 데이터 동기화 메커니즘.',
}

# 데이터 동기화

atproto(즉, "Authenticated Transfer Protocol")의 주요 설계 목표 중 하나는 독립적인 네트워크 서비스 간에 공개 콘텐츠를 안정적으로 분배하는 것입니다. 이 데이터 전송은 신뢰할 수 있어야 하며(암호학적으로 인증됨) 대규모 환경에서도 비교적 낮은 지연(latency)을 유지해야 합니다. 또한 새로운 참가자가 언제든지 네트워크에 참여하여 이전 콘텐츠를 “백필(backfill)”할 수 있어야 합니다.

이 섹션에서는 atproto의 주요 데이터 동기화 기능에 대해 설명합니다. 기본 실시간 데이터 동기화 메커니즘은 리포지토리 이벤트 스트림(일명 "firehose")이며, 기본 배치 데이터 전송 메커니즘은 CAR 파일 형태의 리포지토리 내보내기입니다. 이 두 메커니즘은 결합되어 네트워크의 실시간 동기화 미러(복제본)를 부트스트래핑하는 과정으로 활용될 수 있습니다.

## 동기화 기본 요소

레포지토리 명세에 설명된 바와 같이, 각 리포지토리 커밋에는 TID 형식의 *revision* 번호가 있습니다. 동일 계정에 대한 커밋 간에는, 계정이 호스트 간에 마이그레이션되거나 네트워크에서 활동이 없더라도 revision 번호는 항상 증가해야 합니다. revision 번호는 개별 계정의 동기화를 돕기 위한 논리적 시계로 사용할 수 있습니다. 이를 단순하게 유지하기 위해, 새로운 계정을 생성할 때의 초기 커밋을 포함하여 각 커밋에 대해 현재 시간을 TID로 사용하는 것이 권장됩니다. 서비스는 짧은 오차 범위를 넘어서는 미래 타임스탬프에 해당하는 revision 번호를 거부하거나 무시해야 합니다. 네트워크 서비스는 자신이 관찰한 모든 계정의 커밋 revision을 추적하여 동기화 진행 상황을 검증할 수 있습니다. 데이터를 동기화하는 서비스는 관련 계정의 API 응답 헤더(`Atproto-Repo-Rev`)에 가장 최근에 처리한 revision을 포함시켜, 클라이언트(및 사용자)가 응답이 실제 리포지토리와 최신 상태인지, 동기화에 문제가 없는지를 확인할 수 있도록 할 수 있습니다.

## Firehose

리포지토리 이벤트 스트림(`com.atproto.sync.subscribeRepos`, 일명 "firehose")은 리포지토리 업데이트(`#commit` 이벤트), 핸들 및 DID 문서(`#identity`), 그리고 계정 호스팅 상태(`#account`)를 방송하는 [이벤트 스트림](/specs/event-stream)입니다. PDS 호스트는 로컬에 호스팅된 모든 계정에 대한 업데이트를 포함하는 단일 스트림을 제공합니다. "릴레이"는 하나 이상의 리포 스트림(예: 여러 PDS 인스턴스)을 구독하여 이를 단일 통합 리포 스트림으로 집계하는 네트워크 서비스입니다. 통합 스트림은 동일한 구조와 이벤트 타입을 유지합니다. 네트워크 내 거의 모든 PDS 인스턴스(중간 릴레이를 통해서도 가능)로부터 거의 모든 계정을 집계하는 릴레이는 “전체 네트워크” firehose를 출력합니다. 릴레이는 종종 리포지토리 내용을 미러링하거나 재배포할 수 있지만, 그 핵심 기능은 콘텐츠를 검증하고 통합된 firehose를 제공하는 것입니다.

대부분의 경우 firehose를 통해 동기화되는 리포지토리 데이터는 자기인증(self-certifying)되어(검증 가능한 서명을 포함) 소비자가 별도의 계정 PDS 인스턴스에 추가 요청 없이도 콘텐츠를 검증할 수 있습니다. 다만, 신원(identity) 및 계정 정보는 자기인증되지 않으므로 서비스가 별도로 검증해야 할 수도 있습니다. 이는 보통 독립적인 DID 및 [핸들 확인](/specs/handle)을 의미하며, 계정 호스팅 상태 또한 인프라의 서로 다른 구성 요소 간에 혼동이 없도록 계정 PDS 호스트에서 확인할 수 있습니다.

이벤트 메시지 타입은 `com.atproto.sync.subscribeRepos` Lexicon 스키마에 선언되어 있으며, 아래에 요약되어 있습니다. 몇몇 필드는 모든 이벤트 타입에서 동일합니다 (단, `#commit` 이벤트의 경우 `repo`와 `did`가 다릅니다):

- `seq` (정수, 필수): 이벤트 스트림에 설명된 대로 안정적인 소비를 보장하기 위해 사용됨
- `did` / `repo` (DID 문법의 문자열, 필수): 이벤트와 관련된 계정/신원
- `time` (날짜시간 문자열, 필수): 이벤트가 수신된 대략적인 시각(비공식적이며 권위 있는 정보는 아님). 중간 서비스는 이 필드를 그대로 전달하거나 현재 시각으로 업데이트할 수 있음

### `#identity` 이벤트

지정된 신원(즉, DID 문서나 핸들)에 변경이 *있었을 수도 있음*을 나타내며, 선택적으로 현재 핸들이 무엇인지 포함할 수 있습니다. 단, 어떤 부분이 변경되었는지 또는 신원의 현재 상태가 무엇인지를 확실하게 나타내지는 않습니다.

**이벤트 필드:**

- `seq` (정수, 필수): 모든 이벤트 타입에서 동일
- `did` (DID 문법의 문자열, 필수): 모든 이벤트 타입에서 동일
- `time` (날짜시간 문자열, 필수): 모든 이벤트 타입에서 동일
- `handle` (핸들 문법의 문자열, 선택): 해당 신원의 현재 핸들. 만약 핸들이 올바르게 확인되지 않을 경우 `handle.invalid`일 수 있음

`handle` 필드의 존재 여부는 해당 핸들이 변경되었음을 나타내지 않습니다.

의미와 예상 동작은 다운스트림 서비스가 해당 DID에 대해 캐시된 신원 메타데이터(예: DID 문서 및 핸들)를 업데이트해야 한다는 것입니다. 이들은 캐시를 만료 상태로 표시하거나 즉시 삭제하거나 메타데이터를 재확인할 수 있습니다.

신원 이벤트는 "best-effort" 방식으로 발행됩니다. 어떤 atproto 서비스도 변경을 감지하지 못한 채 DID 문서나 핸들 확인 상태가 변경될 수 있으며, 이 경우 이벤트가 발행되지 않을 수 있습니다. 또한 실제로 아무 것도 변경되지 않았더라도 중복으로 이벤트가 발행될 수 있습니다.

중간 서비스(예: 릴레이)는 다음과 같이 신원 이벤트를 수정하거나 그대로 전달할 수 있습니다:

- 자체 확인 결과로 핸들을 대체하거나, 항상 핸들 필드를 제거하거나, 변경 없이 그대로 전달
- 신원이 실제로 변경되지 않았음을 확인하면 신원 이벤트를 필터링
- 독립적으로 인지한 변경 사항(예: 핸들의 주기적 재검증)을 바탕으로 신원 이벤트를 발행

### `#account` 이벤트

이 이벤트는 이벤트를 발행한 서비스에서 [계정 호스팅 상태](/specs/account)에 변화가 있었을 수 있으며, 새로운 상태가 무엇인지를 나타냅니다. 예를 들어, 계정의 생성, 삭제 또는 일시 중단의 결과일 수 있습니다. 이벤트는 변경된 내용을 설명하는 것이 아니라 현재의 호스팅 상태를 나타냅니다.

**이벤트 필드:**

- `seq` (정수, 필수): 모든 이벤트 타입에서 동일
- `did` (DID 문법의 문자열, 필수): 모든 이벤트 타입에서 동일
- `time` (날짜시간 문자열, 필수): 모든 이벤트 타입에서 동일
- `active` (불리언, 필수): 리포지토리가 현재 사용 가능하며 재배포 가능한지 여부
- `status` (문자열, 선택): 계정 상태를 좀 더 자세히 설명하는 상태 코드. 알려진 값:
  - `takendown`: 서비스 제공자가 약관 또는 정책 위반으로 인해 리포지토리를 무기한 제거함
  - `suspended`: `takendown`의 일시적 또는 시간 제한 변형
  - `deleted`: 계정이 비활성화되었으며, 영구적일 수 있음
  - `deactivated`: 계정 자체에 의해 모든 공개 데이터가 일시적 또는 무기한 제거됨

계정 데이터를 재배포하는 서비스에서 발행된 경우, 이벤트는 해당 서비스에서의 새로운 상태를 나타내며 그 맥락에서 권위적입니다. 즉, 이 이벤트는 리포지토리 호스트 및 미러 간에 홉 단위로 전달됩니다.

자세한 내용은 [계정 호스팅 명세](/specs/account)를 참조하세요.

### `#commit` 이벤트

이 이벤트는 지정된 계정에 대해 새로운 리포지토리 커밋이 있었음을 나타냅니다. 이벤트는 보통 CAR 슬라이스 형식의 리포지토리 데이터 "diff"를 포함합니다. "diff"와 CAR 파일 형식에 대한 자세한 내용은 [레포지토리 명세](/specs/repository)를 참조하세요.

**이벤트 필드:**

- `seq` (정수, 필수): 모든 이벤트 타입에서 동일
- `repo` (DID 문법의 문자열, 필수): 다른 이벤트 타입의 `did`와 동일
- `time` (날짜시간 문자열, 필수): 모든 이벤트 타입에서 동일
- `rev` (TID 형식의 문자열, 필수): 커밋의 revision (커밋 블록 내의 `rev`와 일치해야 함)
- `since` (TID 형식의 문자열, null 허용): 리포 diff가 차이를 포함하는 이전 커밋의 `rev`를 나타냄
- `commit` (CID 링크, 필수): 커밋 객체의 CID (`blocks` 내)
- `tooBig` (불리언, 필수): true인 경우, 리포 diff가 너무 커서 `blocks`, `ops`, 완전한 `blobs`가 모두 포함되지 않았음을 나타냄
- `blocks` (바이트, 필수): 해당 리포 diff에 대한 CAR "slice". 커밋 객체는 반드시 포함되어야 함
- `ops` (객체 배열, 필수): 이 커밋에서 발생한 레코드 수준 작업 목록 (생성, 업데이트, 삭제된 특정 레코드)
- `blobs` (CID 링크 배열, 필수): 이 커밋의 레코드에서 참조하는 새로운 blob들의 집합

계정 리포지토리에 변경이 발생하면 커밋 이벤트가 방송됩니다. 커밋은 "empty"일 수 있는데, 이는 실제 레코드 콘텐츠가 변경되지 않고 오직 `rev`만 증가했음을 의미합니다. 하나의 레코드 업데이트 또는 여러 업데이트를 포함할 수 있습니다. 인증(서명)되는 것은 커밋 객체, 레코드 블록, MST 트리 노드뿐이며, `since`, `ops`, `blobs`, `tooBig` 필드는 자기인증되지 않아 이론적으로 조작되거나 부정확 또는 불완전할 수 있습니다.

만약 `since`가 포함되지 않은 경우, 커밋은 전체 리포 트리를 포함하거나 `tooBig` 플래그를 설정해야 합니다.  
`tooBig` 플래그가 설정되면 업데이트된 데이터 양이 단일 스트림 이벤트 메시지에 직렬화하기에는 너무 많음을 의미하므로, 리포지토리의 완전한 동기화 복사본을 유지하려는 다운스트림 서비스는 diff를 별도로 가져와야 합니다.

### Firehose 검증 모범 사례

업스트림 이벤트를 완전히 검증하는 서비스는 여러 속성을 추적 및 확인해야 합니다. 예를 들어, 릴레이 인스턴스는 PDS 인스턴스로부터 받은 콘텐츠를 재방송하기 전에 완전히 검증해야 합니다.

다음은 검증 규칙 및 권장 동작에 대한 요약입니다:

- 서비스는 각 DID에 대해 신원 데이터를 독립적으로 확인해야 하며, 작동하는 atproto 신원이 없는 계정(예: 서명 키가 없거나, PDS 서비스 항목이 없거나, DID가 폐기된 경우)의 `#commit` 이벤트는 무시해야 합니다.
- PDS 인스턴스에 직접 구독하는 서비스는 각 DID에 대해 권한 있는 PDS를 추적해야 하며, 각 구독(WebSocket)이 연결된 호스트를 기억한 후, 해당 DID의 현재 계정과 일치하지 않는 스트림의 `#commit` 이벤트는 거부해야 합니다.
- 서비스는 각 DID의 계정 호스팅 상태를 추적하고, `active`가 아닌 이벤트의 `#commit`은 무시해야 합니다.
- 서비스는 각 `#commit` 이벤트에 대해 현재 신원 데이터를 사용하여 커밋 서명을 검증해야 합니다. 만약 서명 검증에 실패하면, 신원 메타데이터를 갱신하여 최근 변경되었는지 확인하고, 명백히 잘못된 서명의 이벤트는 거부해야 합니다.
- 서비스는 합리적인 한계를 초과하는 이벤트 메시지를 거부해야 합니다. 생산자에 대한 합리적 상한은 5MB이며, `subscribeRepos` Lexicon은 `blocks`를 1,000,000 바이트, `ops`를 200 항목으로 제한합니다. 데이터가 너무 많은 커밋은 `tooBig` 메커니즘을 사용해야 하며, 이러한 커밋은 가능하면 여러 개의 작은 커밋으로 분할해야 합니다.
- 서비스는 리포지토리 데이터 구조가 명세에 부합하는지 검증해야 하며, 누락된 필드, 잘못된 MST 구조, 또는 기타 프로토콜 위반 시 이벤트를 거부해야 합니다.
- 서비스는 신원, 계정, 커밋 이벤트에 대해 속도 제한을 적용하고, 제한을 위반하는 계정이나 업스트림 서비스를 일시 중단할 수 있습니다. 속도 제한은 잘못된 서명, `tooBig` 이벤트, 누락되거나 순서가 맞지 않는 커밋 등 복구 모드에도 적용될 수 있습니다.
- 서비스는 해당 DID에 대해 가장 최근에 처리한 `rev`보다 낮거나 같은 커밋 이벤트는 무시하고, 몇 분 정도의 시계 오차 범위를 벗어난 미래 타임스탬프의 `rev`를 가진 커밋 이벤트는 거부해야 합니다.
- 서비스는 커밋 이벤트의 `since` 값을 확인하여, 해당 DID에 대해 이전에 본 `rev`와 일치하지 않으면 리포지토리를 동기화되지 않은 상태로 표시해야 합니다(이는 `tooBig` 이벤트와 유사).
- 레코드에 대한 데이터 한계를 검증해야 하며, 손상되었거나 완전히 잘못된 레코드를 포함하는 이벤트는 거부될 수 있습니다 (예: 레코드가 CBOR 형식이 아니거나 정상적인 데이터 크기 제한을 초과하는 경우).
- 서비스에 따라 레코드의 미묘한 데이터 검증을 강제하거나 무시할 수 있습니다. 예를 들어, 레코드에 포함된 지원되지 않는 CID 해시 유형은 릴레이에서는 무시해야 하지만, AppView에서는 레코드나 커밋 이벤트를 거부할 수 있습니다.
- 리포지토리 데이터의 전체 복사본을 보유하는 미러링 서비스는 커밋 diff가 MST 트리를 완전하고 유효한 상태로 남기는지(예: 누락된 레코드 없음, 잘못된 MST 노드 없음, MST 구조를 재생성 시 커밋 CID가 재현 가능함)를 검증해야 합니다.
- 특히 릴레이는 Lexicon에 대해 레코드를 검증해서는 안 됩니다.

## 신뢰할 수 있는 동기화

이 섹션에서는 firehose를 안정적으로 구독하고 네트워크의 동기화된 미러를 유지하는 방법에 대해 설명합니다.

서비스는 일반적으로 데이터를 추적하는 모든 계정에 대해 다음과 같은 상태 정보를 유지해야 합니다:

- 가장 최근에 성공적으로 처리한 커밋 `rev`를 추적
- 캐시된 신원 데이터를 유지하고, 캐시 만료를 통해 주기적으로 해당 데이터를 재검증
- 계정 상태를 추적

어떤 `#identity` 이벤트가 수신될 때마다 신원 캐시는 삭제되어야 합니다. 또한, 커밋 서명 검증에 실패할 경우(예: 서명 키가 업데이트되었으나 캐시가 갱신되지 않은 경우) 신원 확인을 재실시해야 합니다.

firehose에서 `tooBig` 이벤트가 발행되면, 다운스트림 서비스는 대역 외에서 diff를 가져와야 합니다. 이는 보통 해당 계정의 현재 PDS 호스트의 `com.atproto.sync.getRepo` 엔드포인트에 `since` 필드를 포함한 API 요청을 의미합니다. 이때 `since` 값은 해당 계정에 대해 가장 최근에 처리한 `rev` 값이어야 하며, 이는 커밋 이벤트 메시지의 `since` 필드와 일치할 수도, 그렇지 않을 수도 있습니다.

만약 커밋 이벤트의 `since` 값이 해당 계정의 가장 최근 처리 `rev`와 일치하지 않고, 동시에 그 값이 현재 처리한 가장 최신 커밋 `rev`보다 “이후”(더 높은 값)라면, 서비스는 `tooBig` 이벤트와 동일하게 대역 외에서 diff를 가져와야 할 수도 있습니다.

서비스는 업스트림 구독의 `seq` 번호를 추적해야 하며, 이는 단일 릴레이 연결만 있더라도 업스트림별로 별도로 저장되어야 합니다(향후 다른 릴레이로 구독이 변경될 수 있으므로).

이벤트는 병렬로 처리될 수 있으나, 각 계정에 대해서는 순차적으로 순서에 맞게 처리되어야 합니다. 이는 repo DID를 파티션 키로 사용하여 여러 작업자를 분할함으로써 달성할 수 있습니다.

서비스는 PDS 호스트 및 릴레이 인스턴스 등 다른 서비스로부터 리포지토리 DID와 `rev` 번호의 스냅샷을 가져와 콘텐츠를 안정적으로 소비하고 있는지 확인할 수 있습니다. 짧은 지연 후, 이를 현재 상태와 비교하여 예상보다 낮은 `rev` 값을 가진 계정을 식별하고, 해당 리포지토리를 대역 외에서 업데이트할 수 있습니다.

## 실시간 미러 부트스트래핑

firehose는 새로운 데이터 업데이트를 실시간으로 반영하는 데, 리포지토리 내보내기는 스냅샷 용도로 사용할 수 있습니다. 이 둘을 결합하여 완전한 실시간 업데이트 미러를 부트스트래핑하는 것은 다소 까다로울 수 있습니다. 한 가지 접근 방식은 다음과 같습니다.

발견된 모든 계정(DID)에 대해 동기화 상태 테이블을 유지합니다. 상태는 다음과 같이 분류할 수 있습니다:

- `dirty`: 해당 계정에 로컬 리포지토리 데이터가 없거나 동기화가 깨진 상태
- `in-process`: 리포지토리가 "dirty"하지만, 이를 업데이트하기 위한 백그라운드 작업이 진행 중인 상태
- `synchronized`: 리포지토리의 완전한 복사본이 처리된 상태

전체 firehose에 구독을 시작합니다. 만약 계정에 기존 리포지토리 데이터가 없다면 해당 계정을 `dirty`로 표시합니다. 이후, 해당 리포지토리에 새로운 이벤트가 수신되면 계정의 상태에 따라 다음과 같이 처리합니다:

- 상태가 `dirty`인 경우: 이벤트를 무시
- 상태가 `synchronized`인 경우: 이벤트를 즉시 리포 업데이트로 처리
- 상태가 `in-process`인 경우: 이벤트를 로컬 큐에 저장

백그라운드 작업자 집합이 `dirty` 상태의 리포지토리를 처리하기 시작합니다. 우선 해당 계정의 상태를 `in-process`로 전환하여 새로운 이벤트가 큐에 저장되도록 한 후, PDS로부터 전체 리포 내보내기(CAR 파일)를 가져와 전체적으로 처리합니다. 이때 리포 내보내기의 커밋 `rev`를 기록합니다. 전체 리포 가져오기가 완료되면, 작업자는 큐에 저장된 이벤트를 순서대로 처리하며, 기존에 처리된 `rev`보다 낮은 이벤트는 건너뜁니다(일반적인 동작 방식). 해당 계정의 큐가 모두 처리되면 상태를 `synchronized`로 전환하고, 작업자는 다음 작업으로 넘어갑니다.

잠시 후, 대부분의 알려진 계정이 `synchronized`로 표시되겠지만, 이는 네트워크 내에서 가장 최근에 활동한 계정만을 나타낼 수 있습니다. 이후, 예를 들어 기존의 대규모 서비스를 대상으로 API 쿼리를 사용하여 네트워크 내의 보다 완전한 리포지토리 집합을 가져올 수 있습니다. 새로 확인된 계정은 `dirty`로 표시하고, 백그라운드 작업자가 이를 처리하도록 합니다.

모든 계정이 `synchronized` 상태가 되면 부트스트래핑 프로세스가 완료됩니다. 대규모 환경에서는 PDS 인스턴스 다운, 신원 확인 실패, 잘못된 이벤트나 데이터, 서명 등의 이유로 완벽한 동기화를 달성하기 어려울 수 있습니다.

## 사용 및 구현 가이드라인

계정 이벤트별 firehose 이벤트 시퀀싱에 대한 구체적인 가이드라인은 [계정 생애주기 모범 사례 가이드](/guides/account-lifecycle)에 설명되어 있습니다.

## 보안 우려사항

리소스 고갈 공격에 대한 완화 조치(예: 이벤트 속도 제한, 계정별 데이터 할당량, 데이터 객체 크기 및 역직렬화된 데이터 복잡도 제한 등)를 적용하는 것이 권장됩니다.

알 수 없거나 신뢰할 수 없는 호스트에 네트워크 요청을 보낼 때는 특히 주의해야 하며, 해당 호스트의 네트워크 위치가 신뢰할 수 없는 입력에서 온 경우(HTTP 리다이렉트를 포함하여) 로컬 또는 내부 호스트에 연결하지 않도록 URL을 검증하고, 브라우저 컨텍스트에서 SSRF를 피해야 합니다.

트래픽 증폭 공격을 방지하기 위해, 아웃바운드 네트워크 요청은 호스트별로 속도 제한되어야 합니다. 예를 들어, firehose에서 소비할 때 발생하는 신원 확인 요청(여기에는 DNS TXT 트래픽 및 DID 확인 요청이 포함됨)이 해당됩니다.

## 향후 작업

`subscribeRepos` Lexicon은 더 이상 사용되지 않는 필드를 제거하는 방식으로 조정될 가능성이 있으며, 이는 Lexicon 발전 규칙을 깨더라도 적용될 수 있습니다.

이벤트 스트림의 시퀀스/커서 체계는 샤딩, 타임스탬프 기반 재개, 그리고 독립 인스턴스 간의 더 쉬운 장애 조치를 지원하기 위해 개선될 수 있습니다.

전체 인증 firehose의 대안으로, 단순 JSON 직렬화, 레코드 컬렉션 타입에 따른 필터링, MST 노드 생략 등 전체 인증이 필요하지 않거나 원치 않는 사용 사례에서 개발을 단순화하고 리소스 소비를 줄이는 변경사항이 추가될 수 있습니다.
